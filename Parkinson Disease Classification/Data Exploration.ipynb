# -*- coding: utf-8 -*-
"""Healthcare Assignment 6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZH_6gbzB9jSNJWczcF0BEVfJzl-g5sxA
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

dfa = pd.read_csv("training_data.csv")

dfa.shape

dfa.head()

dfa.tail()

dfa.shape

dfa.info()

dfa.isnull().sum()

dfa1 = ["diagnosis_date","gleason_score","age","height","weight","tumor_diagnosis","tumor_6_months",
      "tumor_1_year","psa_diagnosis","psa_6_months","psa_1_year","t_score",
      "n_score","m_score","stage","race","first_degree_history","previous_cancer","side",
      "rd_thrpy","h_thrpy","chm_thrpy","cry_thrpy","brch_thrpy","rad_rem","multi_thrpy","survival_1_year","survival_7_years"]

df = dfa[dfa1]

df

df.shape

cat_cols = ["t_score","n_score","m_score","stage","race","first_degree_history","previous_cancer",
            "side","rd_thrpy","h_thrpy","chm_thrpy","cry_thrpy","brch_thrpy","rad_rem","multi_thrpy","survival_1_year",
            "survival_7_years"]
#cat_cols = ~ df.isin(num_cols)
num_cols = ["gleason_score","age","height","weight","tumor_diagnosis","tumor_6_months",
            "tumor_1_year","psa_diagnosis","psa_6_months","psa_1_year"]

cat_cols

num_cols

plt.figure(figsize =(10,6), dpi=200)
sns.heatmap(df[num_cols].corr(),cmap ="RdYlGn", annot = True)

sns.histplot(data = dfa, x = 'gleason_score', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'age', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'height', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'weight', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'tumor_diagnosis', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'tumor_6_months', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'tumor_1_year', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'psa_diagnosis', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'psa_6_months', bins=20, kde=True, edgecolor='black')
plt.show()

sns.histplot(data=df, x = 'psa_1_year', bins=20, kde=True, edgecolor='black')
plt.show()

df[num_cols].describe()

from scipy.stats import chi2_contingency
# Chi square test for the categorical variables

def get_chi_sq(row, column, df):

    # plot the graph for the data passed
    fig = plt.figure()
    ax = fig.add_subplot(111)
    sns.countplot(data=df, x=row, hue=column)
    plt.xlabel(row)
    plt.ylabel('Count')
    plt.show()
    # doing this to keep from opening too many figs at once (eats memory)
    plt.close(fig);

    # create cross-tabulation
    xtab = pd.crosstab(df[row], df[column], margins = False)
    print('observed data:\n', xtab)

    # Chi-square contingency table
    chi2, p_value, dof, expected = chi2_contingency(xtab, correction = False)
    print('expected data:\n', expected)
    print('chi-squared value: {:.4f} for {:.0f} dof; p-value = {:.4f}\n'.format(chi2, dof, p_value))

# for every category column, doing the Chi-sq test
for cat_var in cat_cols:
  get_chi_sq(cat_var, 'survival_7_years', df)

df1 = ["diagnosis_date","gleason_score","t_score","n_score","m_score","stage","age","race","height","weight","first_degree_history"
       ,"previous_cancer","tumor_diagnosis","tumor_1_year","psa_diagnosis","psa_1_year"
       ,"rd_thrpy","h_thrpy","chm_thrpy","cry_thrpy","brch_thrpy","rad_rem","multi_thrpy","survival_1_year","survival_7_years"]

dff = df[df1]

df[df1].shape

dummies1 = pd.get_dummies(dff.t_score)
dummies1

dummies2 = pd.get_dummies(dff.n_score)
dummies2

dummies3 = pd.get_dummies(dff.m_score)
dummies3

dummies4 = pd.get_dummies(dff.stage)
dummies4

dummies5 = pd.get_dummies(dff.race, prefix = "race")
dummies5

dummies6 = pd.get_dummies(dff.first_degree_history, prefix = "famhis")
dummies6

con_cat = pd.concat([dff, dummies1,dummies2,dummies3,dummies4,dummies5,dummies6], axis =1)
con_cat

con_cat.shape

final = con_cat.drop(columns=["t_score","n_score","m_score","stage","race","first_degree_history"])
final

Dummies_cols = ["T1a","T1b","T1c","T2a","T2b","T2c","T3a","T3b","T3c","T4","N0","N1","NX","M0","M1a","M1b","M1c",
                "I","IIA","IIB","III","IV","race_1.0","race_2.0","race_3.0","race_4.0",
                "famhis_0.0","famhis_1.0","famhis_2.0","famhis_3.0","famhis_4.0"]

from scipy.stats import chi2_contingency
# Chi square test for the categorical variables

def get_chi_sq(row, column, final):

    # plot the graph for the data passed
    fig = plt.figure()
    ax = fig.add_subplot(111)
    sns.countplot(data=final, x=row, hue=column)
    plt.xlabel(row)
    plt.ylabel('Count')
    plt.show()
    # doing this to keep from opening too many figs at once (eats memory)
    plt.close(fig);

    # create cross-tabulation
    xtab = pd.crosstab(final[row], final[column], margins = False)
    print('observed data:\n', xtab)

    # Chi-square contingency table
    chi2, p_value, dof, expected = chi2_contingency(xtab, correction = False)
    print('expected data:\n', expected)
    print('chi-squared value: {:.4f} for {:.0f} dof; p-value = {:.4f}\n'.format(chi2, dof, p_value))

# for every category column, doing the Chi-sq test
for var in Dummies_cols:
  get_chi_sq(var, 'survival_7_years', final)

final1 = final.drop(columns=["NX"])
final1

final2 = final1.drop(columns=["famhis_2.0","famhis_3.0","famhis_4.0","race_2.0","race_3.0","race_4.0"])
final2

final2['bmi'] = final2["weight"] / final2["height"] ** 2
final2

final2.diagnosis_date.dtype

final2[['month', 'year']] = final2['diagnosis_date'].str.split('-', 1, expand=True)

final2

final3 = final2.drop(columns=["height","weight","diagnosis_date"])
final3

final3.isnull().sum()

final3.dropna()

final3["month"].unique()

final3.isna().sum()

final3.replace([np.inf, -np.inf], np.nan, inplace=True)
#Drop rows with NaN
final3.dropna(inplace=True)

final3.isnull().sum()

final3['month'].replace(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'],
                        [1,2,3,4,5,6,7,8,9,10,11,12], inplace=True)

final3

X_train = final3.drop('survival_7_years',axis = 1)
y_train = final3['survival_7_years']

X_train.shape

final3.columns

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
#X_test = sc.transform(X_test)

lr = LogisticRegression()
lr.fit(X_train, y_train)

coef = lr.coef_[0]
intercept = lr.intercept_

intercept

feature_names=['gleason_score', 'age', 'previous_cancer', 'tumor_diagnosis',
       'tumor_1_year', 'psa_diagnosis', 'psa_1_year', 'rd_thrpy', 'h_thrpy',
       'chm_thrpy', 'cry_thrpy', 'brch_thrpy', 'rad_rem', 'multi_thrpy',
       'survival_1_year', 'T1a', 'T1b', 'T1c', 'T2a',
       'T2b', 'T2c', 'T3a', 'T3b', 'T3c', 'T4', 'N0', 'N1', 'M0', 'M1a', 'M1b',
       'M1c', 'I', 'IIA', 'IIB', 'III', 'IV', 'race_1.0', 'famhis_0.0',
       'famhis_1.0', 'bmi', 'month', 'year']

odds_ratios = np.exp(coef)

# Create a dataframe with the feature names, coefficients, and odds ratios
f = pd.DataFrame({'feature': feature_names, 'coefficient': coef, 'odds_ratio': odds_ratios})

f

lr_acc = accuracy_score(y_train, lr.predict(X_train))
print(f"Accuracy Score is {lr_acc}")

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_train,X_train))
print(confusion_matrix(y_train,X_train))

Test = pd.read_csv("(name)_score.csv")

Test.shape

T1 = ["diagnosis_date","gleason_score","t_score","n_score","m_score","stage","age","race","height","weight","first_degree_history"
       ,"previous_cancer","tumor_diagnosis","tumor_1_year","psa_diagnosis","psa_1_year"
       ,"rd_thrpy","h_thrpy","chm_thrpy","cry_thrpy","brch_thrpy","rad_rem","multi_thrpy","survival_1_year","survival_7_years"]

Test1 = Test[T1]

Test1

dummy1 = pd.get_dummies(Test1.t_score)
dummy1

dummy2 = pd.get_dummies(Test1.n_score)
dummy2

dummy3 = pd.get_dummies(Test1.m_score)
dummy3

dummy4 = pd.get_dummies(Test1.stage)
dummy4

dummy5 = pd.get_dummies(Test1.race, prefix = "race")
dummy5

dummy6 = pd.get_dummies(Test1.first_degree_history, prefix = "famhis")
dummy6

con_cat1 = pd.concat([Test1, dummy1,dummy2,dummy3,dummy4,dummy5,dummy6], axis =1)
con_cat1

finTest = con_cat1.drop(columns=["t_score","n_score","m_score","stage","race","first_degree_history"])
finTest

finTest1 = finTest.drop(columns=["NX","famhis_2.0","famhis_3.0","famhis_4.0","famhis_5.0","race_2.0","race_3.0","race_4.0"])
finTest1

finTest1['bmi'] = finTest1["weight"] / finTest1["height"] ** 2
finTest1

finTest1[['month', 'year']] = finTest1['diagnosis_date'].str.split('-', 1, expand=True)
finTest1

finTest1 = finTest1.drop(columns=["height","weight","diagnosis_date"])
finTest1

finTest1['month'].replace(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'],
                        [1,2,3,4,5,6,7,8,9,10,11,12], inplace=True)
finTest1

X_test1 = finTest1.drop('survival_7_years',axis = 1)
y_test1 = finTest1['survival_7_years']

X_test1.isnull().sum()

X_test1.shape

X_Test = X_test1.dropna()
X_Test

X_Test.isnull().sum()

final3.columns

sc = StandardScaler()
#X_train = sc.fit_transform(X_train)
X_Test = sc.fit_transform(X_Test)

y_test1 = lr.predict(X_Test)

y_pred = pd.DataFrame(y_test1)
y_pred

coef = lr.coef_[0]
intercept = lr.intercept_

feature_names=['gleason_score', 'age', 'previous_cancer', 'tumor_diagnosis',
       'tumor_1_year', 'psa_diagnosis', 'psa_1_year', 'rd_thrpy', 'h_thrpy',
       'chm_thrpy', 'cry_thrpy', 'brch_thrpy', 'rad_rem', 'multi_thrpy',
       'survival_1_year', 'T1a', 'T1b', 'T1c', 'T2a',
       'T2b', 'T2c', 'T3a', 'T3b', 'T3c', 'T4', 'N0', 'N1', 'M0', 'M1a', 'M1b',
       'M1c', 'I', 'IIA', 'IIB', 'III', 'IV', 'race_1.0', 'famhis_0.0',
       'famhis_1.0', 'bmi', 'month', 'year']

odds_ratios = np.exp(coef)

# Create a dataframe with the feature names, coefficients, and odds ratios
f_test = pd.DataFrame({'feature': feature_names, 'coefficient': coef, 'odds_ratio': odds_ratios})

f_test

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test1,y_pred))
print(confusion_matrix(y_test1,y_pred))